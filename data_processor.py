import pandas as pd
import numpy as np
from datetime import datetime
import streamlit as st
import re

class DataProcessor:
    def __init__(self):
        self.raw_df = None
        self.processed_df = None

    @staticmethod
    def load_data(file_path, sheet_name):
        """ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Excel"""
        df = pd.read_excel(file_path, sheet_name=sheet_name, header=1)
        if df.empty:
            raise ValueError("Ø§Ù„Ù…Ù„Ù Ù„Ø§ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª")
        st.success(f"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ {len(df)} Ø³Ø¬Ù„ Ø¨Ù†Ø¬Ø§Ø­")
        return df

    # --------- Ù…Ø±Ø§Ø­Ù„ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© ---------
    def preprocess_data(self, df):
        """ØªÙ†Ø¸ÙŠÙ Ø£ÙˆÙ„ÙŠ + Ø£Ù†ÙˆØ§Ø¹ + Ù…ÙÙ‚ÙˆØ¯Ø§Øª"""
        self.raw_df = df.copy()
        df = self.clean_column_names(df)
        df = self.remove_empty_rows(df)
        df = self.clean_data_types(df)
        df = self.handle_missing_values(df)
        self.processed_df = df
        st.success("âœ… ØªÙ… Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ù†Ø¬Ø§Ø­")
        return df

    def clean_column_names(self, df):
        """ØªÙ†Ø¸ÙŠÙ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© (Ù…Ø¹ Ø§Ù„Ø§Ø­ØªÙØ§Ø¸ Ø¨Ø¥Ù…ÙƒØ§Ù†ÙŠØ© Ø¥Ù†Ø´Ø§Ø¡ aliases Ù„Ø§Ø­Ù‚Ø§Ù‹)"""
        df.columns = [str(c).strip().replace('\n', ' ').replace('\r', '') for c in df.columns]
        mapping = {}
        for col in df.columns:
            clean = re.sub(r'[^\w\s]', '', col)
            clean = re.sub(r'\s+', '_', clean.strip())
            mapping[col] = clean
        df = df.rename(columns=mapping)
        return df

    def remove_empty_rows(self, df):
        initial = len(df)
        df = df.dropna(how='all')
        removed = initial - len(df)
        if removed > 0:
            st.info(f"ğŸ“Š ØªÙ… Ø¥Ø²Ø§Ù„Ø© {removed} ØµÙ ÙØ§Ø±Øº")
        return df

    def clean_data_types(self, df):
        # ØªÙˆØ§Ø±ÙŠØ®
        for col in ['Date_Placed_in_Service', 'ØªØ§Ø±ÙŠØ®_Ø§Ù„Ø¯Ø®ÙˆÙ„_ÙÙŠ_Ø§Ù„Ø®Ø¯Ù…Ø©']:
            if col in df.columns:
                df[col] = pd.to_datetime(df[col], errors='coerce', dayfirst=True)
                if df[col].isna().all():
                    df[col] = pd.to_datetime(df[col], errors='coerce', format='%Y-%m-%d %H:%M:%S')
        # Ø£Ø±Ù‚Ø§Ù…
        numeric_cols = [
            'Cost','Ø§Ù„ØªÙƒÙ„ÙØ©','Depreciation_amount','Ù‚Ø³Ø·_Ø§Ù„Ø§Ù‡Ù„Ø§Ùƒ','Net_Book_Value','Ø§Ù„Ù‚ÙŠÙ…Ø©_Ø§Ù„Ø¯ÙØªØ±ÙŠØ©',
            'Useful_Life','Ø§Ù„Ø¹Ù…Ø±_Ø§Ù„Ø¥Ù†ØªØ§Ø¬ÙŠ','Quantity','Ø§Ù„Ø¹Ø¯Ø¯','Residual_Value','Ø§Ù„Ù‚ÙŠÙ…Ø©_Ø§Ù„Ù…ØªØ¨Ù‚ÙŠØ©_ÙÙŠ_Ù†Ù‡Ø§ÙŠØ©_Ø§Ù„Ø¹Ù…Ø±',
            'Accumulated_Depreciation','Ø§Ù„Ø§Ø³ØªÙ‡Ù„Ø§Ùƒ_Ø§Ù„Ù…ØªØ±Ø§ÙƒÙ…'
        ]
        for col in numeric_cols:
            if col in df.columns:
                if df[col].dtype == 'object':
                    df[col] = df[col].astype(str).str.replace(',', '').str.replace(' ', '')
                df[col] = pd.to_numeric(df[col], errors='coerce')
        # Ù†ØµÙˆØµ
        text_cols = [
            'Asset_Description','ÙˆØµÙ_Ø§Ù„Ø£ØµÙ„','Custodian','Ø§Ù„Ù‚Ø³Ù…_Ø£Ùˆ_Ø§Ù„Ø¥Ø¯Ø§Ø±Ø©_Ø§Ù„Ù…Ø³Ø¤ÙˆÙ„Ø©',
            'City','Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©','Level_1_FA_Module_English_Description',
            'Manufacturer','Ø§Ù„Ù…ØµÙ†Ø¹','Tag_number','Ø±Ù‚Ù…_Ø§Ù„Ø¨Ø·Ø§Ù‚Ø©'
        ]
        for col in text_cols:
            if col in df.columns:
                df[col] = df[col].astype(str).str.strip().replace(['Not Available','N/A','nan','None'], '')
        return df

    def handle_missing_values(self, df):
        for col in df.columns:
            if df[col].isna().sum() == 0:
                continue
            if col in ['Cost', 'Depreciation_amount', 'Net_Book_Value']:
                df[col] = df[col].fillna(0)
            elif col in ['Asset_Description', 'Custodian']:
                df[col] = df[col].fillna('ØºÙŠØ± Ù…Ø­Ø¯Ø¯')
        return df

    # Ø­Ø³Ø§Ø¨Ø§Øª Ù…Ø¶Ø§ÙØ© + Ø¥Ø±Ø¬Ø§Ø¹ Ø£Ø¹Ù…Ø¯Ø© Ø¨Ø§Ù„Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ù‚ÙŠØ§Ø³ÙŠØ© (Ø§Ù„Ù…ØªÙˆØ§ÙÙ‚Ø© Ù…Ø¹ asset_models)
    @staticmethod
    def calculate_additional_metrics(df):
        # Ø¹Ù…Ø± Ø§Ù„Ø£ØµÙ„
        if 'Date_Placed_in_Service' in df.columns:
            now = pd.Timestamp.now()
            df['Asset_Age'] = (now - pd.to_datetime(df['Date_Placed_in_Service'])) / np.timedelta64(1, 'Y')
            df['Asset_Age'] = df['Asset_Age'].round(1)
        # Ù†Ø³Ø¨Ø© Ø§Ù„Ø¥Ù‡Ù„Ø§Ùƒ
        if 'Cost' in df.columns and 'Depreciation_amount' in df.columns:
            df['Depreciation_Rate'] = (df['Depreciation_amount'] / df['Cost'] * 100).replace([np.inf, -np.inf], 0).clip(0, 100).round(2)
        # Ø­Ø§Ù„Ø© Ø§Ù„Ø£ØµÙ„
        if 'Depreciation_Rate' in df.columns:
            conds = [df['Depreciation_Rate'] >= 80, df['Depreciation_Rate'] >= 50, df['Depreciation_Rate'] >= 20, df['Depreciation_Rate'] > 0]
            choices = ['Ù‚Ø¯ÙŠÙ…','Ù…ØªÙˆØ³Ø·','Ø¬Ø¯ÙŠØ¯','Ø¬Ø¯ÙŠØ¯ Ø¬Ø¯Ø§Ù‹']
            df['Asset_Condition'] = np.select(conds, choices, default='Ù„Ù… ÙŠØ¨Ø¯Ø£ Ø§Ù„Ø¥Ù‡Ù„Ø§Ùƒ')
        return df

    def standardize_column_aliases(self, df):
        """Ø¥Ù†Ø´Ø§Ø¡ Ø£Ø¹Ù…Ø¯Ø© aliases Ø¨Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ù…Ø³Ø§ÙØ§Øª Ø§Ù„ØªÙŠ ÙŠØªÙˆÙ‚Ø¹Ù‡Ø§ asset_models"""
        aliases = {
            'Date_Placed_in_Service': 'Date Placed in Service',
            'Depreciation_amount': 'Depreciation amount',
            'Net_Book_Value': 'Net Book Value',
            'Useful_Life': 'Useful Life',
            'Asset_Description': 'Asset Description',
            'Tag_number': 'Tag number'
        }
        for src, dst in aliases.items():
            if src in df.columns and dst not in df.columns:
                df[dst] = df[src]
        return df
