# -*- coding: utf-8 -*-
import pandas as pd
import numpy as np
from datetime import datetime
import streamlit as st
import re

class DataProcessor:
    def __init__(self):
        self.raw_df = None
        self.processed_df = None

    # -------------------------------------------------
    # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    # -------------------------------------------------
    @staticmethod
    def load_data(file_path, sheet_name):
        """ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ù…Ù„Ù Excel"""
        try:
            # ÙÙŠ ÙƒØ«ÙŠØ± Ù…Ù† Ù…Ù„ÙØ§Øª FAR ÙŠÙƒÙˆÙ† Ø£ÙˆÙ„ ØµÙ Ù‡Ùˆ Ø¹Ù†Ø§ÙˆÙŠÙ† Ø¹Ø±Ø¨ÙŠØ©/Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ© Ù…Ø²Ø¯ÙˆØ¬Ø©
            # Ù„Ø°Ø§ Ù†Ø¨Ø¯Ø£ Ù…Ù† Ø§Ù„Ø³Ø·Ø± Ø§Ù„Ø«Ø§Ù†ÙŠ ØºØ§Ù„Ø¨Ø§Ù‹ (header=1). Ø¹Ø¯Ù‘Ù„Ù‡Ø§ Ù„Ùˆ Ø§Ø­ØªØ¬Øª.
            df = pd.read_excel(file_path, sheet_name=sheet_name, header=1)

            if df.empty:
                raise ValueError("Ø§Ù„Ù…Ù„Ù Ù„Ø§ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª")

            st.success(f"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ {len(df)} Ø³Ø¬Ù„ Ø¨Ù†Ø¬Ø§Ø­")
            return df

        except FileNotFoundError:
            st.error("âŒ Ù…Ù„Ù Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯")
            raise
        except Exception as e:
            st.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {str(e)}")
            raise

    # -------------------------------------------------
    # Ø®Ø· Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ
    # -------------------------------------------------
    def preprocess_data(self, df):
        """Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ø³Ø¨Ù‚Ø© Ù„Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
        try:
            self.raw_df = df.copy()

            # 1) ØªÙ†Ø¸ÙŠÙ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©
            df = self.clean_column_names(df)

            # 2) Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØµÙÙˆÙ Ø§Ù„ÙØ§Ø±ØºØ© ØªÙ…Ø§Ù…Ø§Ù‹
            df = self.remove_empty_rows(df)

            # 3) ØªÙ†Ø¸ÙŠÙ Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            df = self.clean_data_types(df)

            # 4) Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø©
            df = self.handle_missing_values(df)

            # 5) Ø¥Ø¶Ø§ÙØ© Ø£Ø¹Ù…Ø¯Ø© Ù…Ø­Ø³ÙˆØ¨Ø© (Ø§Ù„Ø¹Ù…Ø±ØŒ Ø§Ù„Ù†Ø³Ø¨ØŒ Ø§Ù„ØªØµÙ†ÙŠÙØ§Øª..)
            df = self.calculate_additional_metrics(df)

            # 6) Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø¬ÙˆØ¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            self.validate_data_quality(df)

            self.processed_df = df
            st.success("âœ… ØªÙ… Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ù†Ø¬Ø§Ø­")
            return df

        except Exception as e:
            st.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {str(e)}")
            raise

    # -------------------------------------------------
    # ØªÙ†Ø¸ÙŠÙ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©
    # -------------------------------------------------
    def clean_column_names(self, df):
        """ØªÙ†Ø¸ÙŠÙ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© (Ø¥Ø²Ø§Ù„Ø© Ø±Ù…ÙˆØ²/Ø£Ø³Ø·Ø± Ø¬Ø¯ÙŠØ¯Ø© ÙˆØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù…Ø³Ø§ÙØ§Øª Ø¥Ù„Ù‰ _)"""
        try:
            df.columns = [str(col).strip().replace('\n', ' ').replace('\r', '') for col in df.columns]

            mapping = {}
            for col in df.columns:
                # Ø¥Ø²Ø§Ù„Ø© Ø£ÙŠ Ø±Ù…ÙˆØ² Ø®Ø§ØµØ©
                new_col = re.sub(r'[^\w\s]', '', col)
                # Ø§Ø³ØªØ¨Ø¯Ø§Ù„ Ø§Ù„Ù…Ø³Ø§ÙØ§Øª Ø¨Ø´Ø±Ø·Ø© Ø³ÙÙ„ÙŠØ©
                new_col = re.sub(r'\s+', '_', new_col.strip())
                mapping[col] = new_col

            df = df.rename(columns=mapping)
            return df

        except Exception as e:
            st.warning(f"âš ï¸ ØªØ­Ø°ÙŠØ± ÙÙŠ ØªÙ†Ø¸ÙŠÙ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©: {str(e)}")
            return df

    # -------------------------------------------------
    # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØµÙÙˆÙ Ø§Ù„ÙØ§Ø±ØºØ©
    # -------------------------------------------------
    def remove_empty_rows(self, df):
        """Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØµÙÙˆÙ Ø§Ù„ÙØ§Ø±ØºØ© ØªÙ…Ø§Ù…Ø§Ù‹"""
        try:
            initial = len(df)
            df = df.dropna(how='all')
            removed = initial - len(df)
            if removed > 0:
                st.info(f"ğŸ“Š ØªÙ… Ø¥Ø²Ø§Ù„Ø© {removed} ØµÙ ÙØ§Ø±Øº")
            return df
        except Exception as e:
            st.warning(f"âš ï¸ ØªØ­Ø°ÙŠØ± ÙÙŠ Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØµÙÙˆÙ Ø§Ù„ÙØ§Ø±ØºØ©: {str(e)}")
            return df

    # -------------------------------------------------
    # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø£Ù†ÙˆØ§Ø¹
    # -------------------------------------------------
    def clean_data_types(self, df):
        """ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØªÙˆØ§Ø±ÙŠØ® ÙˆØ§Ù„Ø£Ø¹Ø¯Ø§Ø¯ ÙˆØ§Ù„Ù†ØµÙˆØµ Ù„Ø£Ø´ÙƒØ§Ù„ Ù…Ù†Ø§Ø³Ø¨Ø©"""
        try:
            # Ø§Ù„ØªÙˆØ§Ø±ÙŠØ®
            date_cols = ['Date_Placed_in_Service', 'ØªØ§Ø±ÙŠØ®_Ø§Ù„Ø¯Ø®ÙˆÙ„_ÙÙŠ_Ø§Ù„Ø®Ø¯Ù…Ø©']
            for col in date_cols:
                if col in df.columns:
                    df[col] = pd.to_datetime(df[col], errors='coerce', dayfirst=True)
                    if df[col].isna().all():
                        # Ù…Ø­Ø§ÙˆÙ„Ø© Ù„Ø§Ø­Ù‚Ø© Ø¨ØµÙŠØºØ© Ù…Ø®ØªÙ„ÙØ©
                        df[col] = pd.to_datetime(df[col], errors='coerce', format='%Y-%m-%d %H:%M:%S')

            # Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø±Ù‚Ù…ÙŠØ© Ø§Ù„Ø´Ø§Ø¦Ø¹Ø© Ø¨Ø§Ø³Ù…Ø§Ø¦Ù‡Ø§ Ø¨Ø¹Ø¯ Ø§Ù„ØªÙ†Ø¸ÙŠÙ
            numeric_cols = [
                'Cost', 'Ø§Ù„ØªÙƒÙ„ÙØ©',
                'Depreciation_amount', 'Ù‚Ø³Ø·_Ø§Ù„Ø§Ù‡Ù„Ø§Ùƒ',
                'Net_Book_Value', 'Ø§Ù„Ù‚ÙŠÙ…Ø©_Ø§Ù„Ø¯ÙØªØ±ÙŠØ©',
                'Useful_Life', 'Ø§Ù„Ø¹Ù…Ø±_Ø§Ù„Ø¥Ù†ØªØ§Ø¬ÙŠ',
                'Quantity', 'Ø§Ù„Ø¹Ø¯Ø¯',
                'Residual_Value', 'Ø§Ù„Ù‚ÙŠÙ…Ø©_Ø§Ù„Ù…ØªØ¨Ù‚ÙŠØ©_ÙÙŠ_Ù†Ù‡Ø§ÙŠØ©_Ø§Ù„Ø¹Ù…Ø±',
                'Accumulated_Depreciation', 'Ø§Ù„Ø§Ø³ØªÙ‡Ù„Ø§Ùƒ_Ø§Ù„Ù…ØªØ±Ø§ÙƒÙ…'
            ]

            for col in numeric_cols:
                if col in df.columns:
                    if df[col].dtype == 'object':
                        df[col] = (
                            df[col].astype(str)
                                  .str.replace(',', '', regex=False)
                                  .str.replace(' ', '', regex=False)
                        )
                    df[col] = pd.to_numeric(df[col], errors='coerce')

            # Ù†ØµÙˆØµ
            text_cols = [
                'Asset_Description', 'ÙˆØµÙ_Ø§Ù„Ø£ØµÙ„',
                'Custodian', 'Ø§Ù„Ù‚Ø³Ù…_Ø£Ùˆ_Ø§Ù„Ø¥Ø¯Ø§Ø±Ø©_Ø§Ù„Ù…Ø³Ø¤ÙˆÙ„Ø©',
                'City', 'Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©',
                'Level_1_FA_Module_-_English_Description',
                'Manufacturer', 'Ø§Ù„Ù…ØµÙ†Ø¹',
                'Tag_number', 'Ø±Ù‚Ù…_Ø§Ù„Ø¨Ø·Ø§Ù‚Ø©'
            ]
            for col in text_cols:
                if col in df.columns:
                    df[col] = df[col].astype(str).str.strip()
                    df[col] = df[col].replace(['Not Available', 'N/A', 'nan', 'None'], '')

            return df

        except Exception as e:
            st.warning(f"âš ï¸ ØªØ­Ø°ÙŠØ± ÙÙŠ ØªÙ†Ø¸ÙŠÙ Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {str(e)}")
            return df

    # -------------------------------------------------
    # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø©
    # -------------------------------------------------
    def handle_missing_values(self, df):
        """Ù…Ù„Ø¡/Ø¹Ø±Ø¶ ØªÙ‚Ø±ÙŠØ± Ø¹Ù† Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø©"""
        try:
            missing_report = {}
            for col in df.columns:
                n = df[col].isna().sum()
                if n > 0:
                    pct = (n / len(df)) * 100
                    missing_report[col] = {'count': n, 'percentage': round(pct, 2)}

                    if col in ['Cost', 'Depreciation_amount', 'Net_Book_Value']:
                        df[col] = df[col].fillna(0)
                    elif col in ['Asset_Description', 'Custodian']:
                        df[col] = df[col].fillna('ØºÙŠØ± Ù…Ø­Ø¯Ø¯')

            if missing_report:
                st.warning("âš ï¸ ÙŠÙˆØ¬Ø¯ Ù‚ÙŠÙ… Ù…ÙÙ‚ÙˆØ¯Ø© ÙÙŠ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª")
                # Ø¹Ø±Ø¶ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø°Ø§Øª Ø§Ù„Ù†Ø³Ø¨ Ø§Ù„Ø£Ø¹Ù„Ù‰ ÙÙ‚Ø· Ù„Ù„Ø§Ø®ØªØµØ§Ø±
                for col, info in missing_report.items():
                    if info['percentage'] > 5:
                        st.write(f"   - {col}: {info['count']} Ù‚ÙŠÙ… Ù…ÙÙ‚ÙˆØ¯Ø© ({info['percentage']}%)")

            return df

        except Exception as e:
            st.warning(f"âš ï¸ ØªØ­Ø°ÙŠØ± ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø©: {str(e)}")
            return df

    # -------------------------------------------------
    # Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…Ø­Ø³ÙˆØ¨Ø© (Ø§Ù„Ø¥ØµØ¯Ø§Ø± Ø§Ù„Ù…Ø¹ØªÙ…Ø¯)
    # -------------------------------------------------
    @staticmethod
def calculate_additional_metrics(df):
        """Ø¥Ø¶Ø§ÙØ© Ø£Ø¹Ù…Ø¯Ø© Ù…Ø­Ø³ÙˆØ¨Ø© Ù…Ø«Ù„ Ø§Ù„Ø¹Ù…Ø± ÙˆÙ†Ø³Ø¨Ø© Ø§Ù„Ø¥Ù‡Ù„Ø§Ùƒ ÙˆØ§Ù„ØªØµÙ†ÙŠÙØ§Øª"""
        try:
            # 1) Ø­Ø³Ø§Ø¨ Ø¹Ù…Ø± Ø§Ù„Ø£ØµÙ„ (Ø¨Ø§Ù„Ø³Ù†ÙˆØ§Øª) Ø¨Ø¯ÙˆÙ† Ø§Ø³ØªØ®Ø¯Ø§Ù… ÙˆØ­Ø¯Ø© 'Y'
            #    Ù†Ø­ÙˆÙ„ Ø§Ù„ÙØ±Ù‚ Ø¥Ù„Ù‰ Ø£ÙŠØ§Ù… Ø«Ù… Ù†Ù‚Ø³Ù… Ø¹Ù„Ù‰ 365.25
            if 'Date_Placed_in_Service' in df.columns:
                now = pd.Timestamp.now()
                age_days = (now - pd.to_datetime(df['Date_Placed_in_Service'], errors='coerce')).dt.days
                df['Asset_Age'] = (age_days / 365.25).round(1)
            else:
                # Ø¥Ù† Ù„Ù… ØªØªÙˆÙØ±ØŒ Ø§Ø¬Ø¹Ù„Ù‡Ø§ ØµÙØ± Ù„ØªØ¬Ù†Ø¨ Ø£Ø®Ø·Ø§Ø¡ Ù„Ø§Ø­Ù‚Ø©
                df['Asset_Age'] = 0.0

            # 2) Ù†Ø³Ø¨Ø© Ø§Ù„Ø¥Ù‡Ù„Ø§Ùƒ
            if 'Cost' in df.columns and 'Depreciation_amount' in df.columns:
                df['Depreciation_Rate'] = (df['Depreciation_amount'] / df['Cost']) * 100
                df['Depreciation_Rate'] = df['Depreciation_Rate'].replace([np.inf, -np.inf], np.nan).fillna(0)
                df['Depreciation_Rate'] = df['Depreciation_Rate'].clip(0, 100).round(2)

            # 3) ØªØµÙ†ÙŠÙ Ø­Ø§Ù„Ø© Ø§Ù„Ø£ØµÙ„
            if 'Depreciation_Rate' in df.columns:
                conds = [
                    df['Depreciation_Rate'] >= 80,
                    df['Depreciation_Rate'] >= 50,
                    df['Depreciation_Rate'] >= 20,
                    df['Depreciation_Rate'] > 0
                ]
                labels = ['Ù‚Ø¯ÙŠÙ…', 'Ù…ØªÙˆØ³Ø·', 'Ø¬Ø¯ÙŠØ¯', 'Ø¬Ø¯ÙŠØ¯ Ø¬Ø¯Ø§Ù‹']
                df['Asset_Condition'] = np.select(conds, labels, default='Ù„Ù… ÙŠØ¨Ø¯Ø£ Ø§Ù„Ø¥Ù‡Ù„Ø§Ùƒ')

            # 4) ØªØµÙ†ÙŠÙ Ù‚ÙŠÙ…Ø© Ø§Ù„Ø£ØµÙ„
            if 'Cost' in df.columns:
                conds = [df['Cost'] >= 10000, df['Cost'] >= 5000, df['Cost'] >= 1000]
                labels = ['Ø¹Ø§Ù„ÙŠØ©', 'Ù…ØªÙˆØ³Ø·Ø©', 'Ù…Ù†Ø®ÙØ¶Ø©']
                df['Value_Category'] = np.select(conds, labels, default='very_low')

            # 5) Ø§Ù„Ø¹Ù…Ø± Ø§Ù„Ù…ØªØ¨Ù‚ÙŠ
            if 'Useful_Life' in df.columns:
                df['Remaining_Life'] = (df['Useful_Life'] - df['Asset_Age']).round(1)
                df['Remaining_Life'] = df['Remaining_Life'].clip(lower=0)

            # 6) Ø³Ù†Ø© Ø§Ù„ØªØ´ØºÙŠÙ„
            if 'Date_Placed_in_Service' in df.columns:
                d = pd.to_datetime(df['Date_Placed_in_Service'], errors='coerce')
                df['Service_Year'] = d.dt.year

            st.info("ğŸ“ˆ ØªÙ… Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…Ø­Ø³ÙˆØ¨Ø© Ø¨Ù†Ø¬Ø§Ø­")
            return df

        except Exception as e:
            st.warning(f"âš ï¸ ØªØ­Ø°ÙŠØ± ÙÙŠ Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…Ø­Ø³ÙˆØ¨Ø©: {str(e)}")
            return df

    # -------------------------------------------------
    # ØªÙˆØ§ÙÙ‚ Ø®Ù„ÙÙŠ Ù…Ø¹ Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ app.py
    # -------------------------------------------------
    def add_calculated_columns(self, df):
        """ØªÙˆØ§ÙÙ‚: Ø§Ø³Ù… Ù‚Ø¯ÙŠÙ… ÙŠØ³ØªØ¯Ø¹ÙŠ Ù†ÙØ³ Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø­Ø§Ù„ÙŠØ©"""
        return self.calculate_additional_metrics(df)

    # -------------------------------------------------
    # ÙØ­ÙˆØµ Ø¬ÙˆØ¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    # -------------------------------------------------
    def validate_data_quality(self, df):
        """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø¬ÙˆØ¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
        try:
            issues = []

            if 'Cost' in df.columns:
                neg = df[df['Cost'] < 0]
                if len(neg) > 0:
                    issues.append(f"âŒ ØªÙƒØ§Ù„ÙŠÙ Ø³Ù„Ø¨ÙŠØ©: {len(neg)} Ø³Ø¬Ù„")

            if 'Cost' in df.columns and 'Depreciation_amount' in df.columns:
                over = df[df['Depreciation_amount'] > df['Cost']]
                if len(over) > 0:
                    issues.append(f"âŒ Ø¥Ù‡Ù„Ø§Ùƒ Ø²Ø§Ø¦Ø¯ Ø¹Ù† Ø§Ù„ØªÙƒÙ„ÙØ©: {len(over)} Ø³Ø¬Ù„")

            if 'Net_Book_Value' in df.columns:
                nbv_neg = df[df['Net_Book_Value'] < 0]
                if len(nbv_neg) > 0:
                    issues.append(f"âŒ Ù‚ÙŠÙ… Ø¯ÙØªØ±ÙŠØ© Ø³Ù„Ø¨ÙŠØ©: {len(nbv_neg)} Ø³Ø¬Ù„")

            if 'Asset_Age' in df.columns:
                age_neg = df[df['Asset_Age'] < 0]
                if len(age_neg) > 0:
                    issues.append(f"âŒ Ø£Ø¹Ù…Ø§Ø± Ø³Ù„Ø¨ÙŠØ©: {len(age_neg)} Ø³Ø¬Ù„")

            if 'Tag_number' in df.columns:
                dup = df[df.duplicated('Tag_number', keep=False)]
                if len(dup) > 0:
                    issues.append(f"âŒ Ø£Ø±Ù‚Ø§Ù… Ø¨Ø·Ø§Ù‚Ø§Øª Ù…ÙƒØ±Ø±Ø©: {len(dup)} Ø³Ø¬Ù„")

            if issues:
                st.warning("âš ï¸ Ù…Ø´Ø§ÙƒÙ„ ÙÙŠ Ø¬ÙˆØ¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª:")
                for i in issues:
                    st.write(f"   {i}")
            else:
                st.success("âœ… Ø¬ÙˆØ¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù…ØªØ§Ø²Ø©")

            return issues

        except Exception as e:
            st.warning(f"âš ï¸ ØªØ­Ø°ÙŠØ± ÙÙŠ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø¬ÙˆØ¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {str(e)}")
            return []

    # -------------------------------------------------
    # Ù…Ù„Ø®Øµ/ØªØµØ¯ÙŠØ±/ØªØµÙÙŠØ©
    # -------------------------------------------------
    def get_data_summary(self, df):
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù…Ù„Ø®Øµ Ù„Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
        try:
            summary = {
                'total_records': len(df),
                'total_columns': len(df.columns),
                'data_types': df.dtypes.value_counts().to_dict(),
                'date_range': None,
                'cost_range': None
            }

            if 'Date_Placed_in_Service' in df.columns:
                d = pd.to_datetime(df['Date_Placed_in_Service'], errors='coerce')
                summary['date_range'] = {'min': d.min(), 'max': d.max()}

            if 'Cost' in df.columns:
                summary['cost_range'] = {
                    'min': float(pd.to_numeric(df['Cost'], errors='coerce').min()),
                    'max': float(pd.to_numeric(df['Cost'], errors='coerce').max()),
                    'total': float(pd.to_numeric(df['Cost'], errors='coerce').sum())
                }

            return summary

        except Exception as e:
            st.warning(f"âš ï¸ ØªØ­Ø°ÙŠØ± ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ø®Øµ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {str(e)}")
            return {}

    def export_processed_data(self, df, file_path):
        """ØªØµØ¯ÙŠØ± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©"""
        try:
            df.to_excel(file_path, index=False)
            st.success(f"âœ… ØªÙ… ØªØµØ¯ÙŠØ± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¥Ù„Ù‰ {file_path}")
            return True
        except Exception as e:
            st.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØµØ¯ÙŠØ± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {str(e)}")
            return False

    def filter_data(self, df, filters):
        """ØªØµÙÙŠØ© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø­Ø³Ø¨ Ù…Ø¹Ø§ÙŠÙŠØ± Ù…Ø­Ø¯Ø¯Ø©"""
        try:
            out = df.copy()
            for column, value in filters.items():
                if value and column in out.columns:
                    if isinstance(value, (int, float)):
                        out = out[out[column] == value]
                    else:
                        out = out[out[column].astype(str).str.contains(str(value), case=False, na=False)]
            return out
        except Exception as e:
            st.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØµÙÙŠØ© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {str(e)}")
            return df


# -----------------------------------------------------
# Ø£Ø¯ÙˆØ§Øª Ø§Ù„ØªØ­Ù‚Ù‚ Ø§Ù„Ø¥Ø¶Ø§ÙÙŠØ©
# -----------------------------------------------------
class DataValidator:
    @staticmethod
    def validate_asset_data(df):
        """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø£ØµÙˆÙ„"""
        results = {'passed': [], 'warnings': [], 'errors': []}
        try:
            required = ['Cost', 'Asset_Description', 'Tag_number']
            for col in required:
                if col not in df.columns:
                    results['errors'].append(f"Ø§Ù„Ø¹Ù…ÙˆØ¯ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ '{col}' ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯")

            if 'Tag_number' in df.columns:
                dup = df[df.duplicated('Tag_number', keep=False)]
                if len(dup) > 0:
                    results['warnings'].append(f"ÙŠÙˆØ¬Ø¯ {len(dup)} Ø±Ù‚Ù… Ø¨Ø·Ø§Ù‚Ø© Ù…ÙƒØ±Ø±")

            for col in ['Cost', 'Depreciation_amount', 'Net_Book_Value']:
                if col in df.columns:
                    if df[col].isna().any():
                        results['warnings'].append(f"ÙŠÙˆØ¬Ø¯ Ù‚ÙŠÙ… Ù…ÙÙ‚ÙˆØ¯Ø© ÙÙŠ {col}")
                    if (df[col] < 0).any():
                        results['warnings'].append(f"ÙŠÙˆØ¬Ø¯ Ù‚ÙŠÙ… Ø³Ù„Ø¨ÙŠØ© ÙÙŠ {col}")

            if not results['errors']:
                results['passed'].append("Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© Ù†Ø¬Ø­Øª")
            return results

        except Exception as e:
            results['errors'].append(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {str(e)}")
            return results


# -----------------------------------------------------
# ØªÙ‚Ø§Ø±ÙŠØ± ÙˆØ£Ù†Ù…Ø§Ø·
# -----------------------------------------------------
def detect_data_patterns(df):
    """ÙƒØ´Ù Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (Ø³Ù†ÙˆÙŠ/Ù…Ø¯Ù†/ØªØµÙ†ÙŠÙØ§Øª)"""
    patterns = {}
    try:
        if 'Service_Year' in df.columns:
            patterns['yearly_distribution'] = df['Service_Year'].value_counts().sort_index().to_dict()
        if 'City' in df.columns:
            patterns['city_distribution'] = df['City'].value_counts().to_dict()
        if 'Level_1_FA_Module_-_English_Description' in df.columns:
            patterns['category_distribution'] = df['Level_1_FA_Module_-_English_Description'].value_counts().to_dict()
        return patterns
    except Exception as e:
        st.warning(f"âš ï¸ ØªØ­Ø°ÙŠØ± ÙÙŠ ÙƒØ´Ù Ø§Ù„Ø£Ù†Ù…Ø§Ø·: {str(e)}")
        return {}

def generate_data_report(df):
    """Ø¥Ù†Ø´Ø§Ø¡ ØªÙ‚Ø±ÙŠØ± Ø´Ø§Ù…Ù„ Ø¹Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
    return {
        'basic_info': {
            'total_records': len(df),
            'total_columns': len(df.columns),
            'memory_usage': float(df.memory_usage(deep=True).sum()) / (1024 ** 2)  # MB
        },
        'data_quality': {},
        'patterns': detect_data_patterns(df)
    }
