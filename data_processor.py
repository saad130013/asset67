import pandas as pd
import numpy as np
from datetime import datetime
import streamlit as st
import re

class DataProcessor:
    def __init__(self):
        self.raw_df = None
        self.processed_df = None
        
    @staticmethod
    def load_data(file_path, sheet_name):
        """ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ù…Ù„Ù Excel"""
        try:
            # Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø¹ ØªØ®Ø·ÙŠ Ø§Ù„ØµÙÙˆÙ Ø§Ù„ÙØ§Ø±ØºØ© ÙÙŠ Ø§Ù„Ø¨Ø¯Ø§ÙŠØ©
            df = pd.read_excel(file_path, sheet_name=sheet_name, header=1)
            
            if df.empty:
                raise ValueError("Ø§Ù„Ù…Ù„Ù Ù„Ø§ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª")
                
            st.success(f"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ {len(df)} Ø³Ø¬Ù„ Ø¨Ù†Ø¬Ø§Ø­")
            return df
            
        except FileNotFoundError:
            st.error("âŒ Ù…Ù„Ù Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯")
            raise
        except Exception as e:
            st.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {str(e)}")
            raise
    
    def preprocess_data(self, df):
        """Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ø³Ø¨Ù‚Ø© Ù„Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
        try:
            self.raw_df = df.copy()
            
            # 1. ØªÙ†Ø¸ÙŠÙ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©
            df = self.clean_column_names(df)
            
            # 2. Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØµÙÙˆÙ Ø§Ù„ÙØ§Ø±ØºØ© ØªÙ…Ø§Ù…Ø§Ù‹
            df = self.remove_empty_rows(df)
            
            # 3. ØªÙ†Ø¸ÙŠÙ Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            df = self.clean_data_types(df)
            
            # 4. Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø©
            df = self.handle_missing_values(df)
            
            # 5. Ø¥Ø¶Ø§ÙØ© Ø£Ø¹Ù…Ø¯Ø© Ù…Ø­Ø³ÙˆØ¨Ø©
            df = self.add_calculated_columns(df)
            
            # 6. Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø¬ÙˆØ¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            self.validate_data_quality(df)
            
            self.processed_df = df
            st.success("âœ… ØªÙ… Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ù†Ø¬Ø§Ø­")
            return df
            
        except Exception as e:
            st.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {str(e)}")
            raise
    
    def clean_column_names(self, df):
        """ØªÙ†Ø¸ÙŠÙ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©"""
        try:
            # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ù…Ø³Ø§ÙØ§Øª Ø§Ù„Ø²Ø§Ø¦Ø¯Ø© ÙˆØ±Ù…ÙˆØ² Ø®Ø§ØµØ©
            df.columns = [str(col).strip().replace('\n', ' ').replace('\r', '') for col in df.columns]
            
            # Ø§Ø³ØªØ¨Ø¯Ø§Ù„ Ø§Ù„Ù…Ø³Ø§ÙØ§Øª Ø¨Ù†Ù‚Ø§Ø· Ø³ÙÙ„ÙŠ Ù„Ù„ØªØ¹Ø§Ù…Ù„ Ø§Ù„Ø£Ø³Ù‡Ù„
            clean_columns = {}
            for col in df.columns:
                clean_col = re.sub(r'[^\w\s]', '', col)  # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø±Ù…ÙˆØ² Ø§Ù„Ø®Ø§ØµØ©
                clean_col = re.sub(r'\s+', '_', clean_col.strip())  # Ø§Ø³ØªØ¨Ø¯Ø§Ù„ Ø§Ù„Ù…Ø³Ø§ÙØ§Øª
                clean_columns[col] = clean_col
            
            df = df.rename(columns=clean_columns)
            return df
            
        except Exception as e:
            st.warning(f"âš ï¸ ØªØ­Ø°ÙŠØ± ÙÙŠ ØªÙ†Ø¸ÙŠÙ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©: {str(e)}")
            return df
    
    def remove_empty_rows(self, df):
        """Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØµÙÙˆÙ Ø§Ù„ÙØ§Ø±ØºØ© ØªÙ…Ø§Ù…Ø§Ù‹"""
        try:
            # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØµÙÙˆÙ Ø§Ù„ØªÙŠ ØªÙƒÙˆÙ† Ø¬Ù…ÙŠØ¹ Ù‚ÙŠÙ…Ù‡Ø§ ÙØ§Ø±ØºØ©
            initial_count = len(df)
            df = df.dropna(how='all')
            removed_count = initial_count - len(df)
            
            if removed_count > 0:
                st.info(f"ğŸ“Š ØªÙ… Ø¥Ø²Ø§Ù„Ø© {removed_count} ØµÙ ÙØ§Ø±Øº")
                
            return df
            
        except Exception as e:
            st.warning(f"âš ï¸ ØªØ­Ø°ÙŠØ± ÙÙŠ Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØµÙÙˆÙ Ø§Ù„ÙØ§Ø±ØºØ©: {str(e)}")
            return df
    
    def clean_data_types(self, df):
        """ØªÙ†Ø¸ÙŠÙ Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
        try:
            # ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØªÙˆØ§Ø±ÙŠØ®
            date_columns = ['Date_Placed_in_Service', 'ØªØ§Ø±ÙŠØ® Ø§Ù„Ø¯Ø®ÙˆÙ„ ÙÙŠ Ø§Ù„Ø®Ø¯Ù…Ø©']
            for col in date_columns:
                if col in df.columns:
                    df[col] = pd.to_datetime(df[col], errors='coerce', dayfirst=True)
                    # Ø¥Ø°Ø§ ÙØ´Ù„ Ø§Ù„ØªØ­ÙˆÙŠÙ„ØŒ Ø­Ø§ÙˆÙ„ Ø¨ØµÙŠØº Ø£Ø®Ø±Ù‰
                    if df[col].isna().all():
                        df[col] = pd.to_datetime(df[col], errors='coerce', format='%Y-%m-%d %H:%M:%S')
            
            # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø±Ù‚Ù…ÙŠØ©
            numeric_columns = [
                'Cost', 'Ø§Ù„ØªÙƒÙ„ÙØ©', 
                'Depreciation_amount', 'Ù‚Ø³Ø· Ø§Ù„Ø§Ù‡Ù„Ø§Ùƒ',
                'Net_Book_Value', 'Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ø¯ÙØªØ±ÙŠØ©',
                'Useful_Life', 'Ø§Ù„Ø¹Ù…Ø± Ø§Ù„Ø¥Ù†ØªØ§Ø¬ÙŠ',
                'Quantity', 'Ø§Ù„Ø¹Ø¯Ø¯',
                'Residual_Value', 'Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ù…ØªØ¨Ù‚ÙŠØ© ÙÙŠ Ù†Ù‡Ø§ÙŠØ© Ø§Ù„Ø¹Ù…Ø±',
                'Accumulated_Depreciation', 'Ø§Ù„Ø§Ø³ØªÙ‡Ù„Ø§Ùƒ Ø§Ù„Ù…ØªØ±Ø§ÙƒÙ…'
            ]
            
            for col in numeric_columns:
                if col in df.columns:
                    # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†ØµÙˆØµ Ù‚Ø¨Ù„ Ø§Ù„ØªØ­ÙˆÙŠÙ„
                    if df[col].dtype == 'object':
                        df[col] = df[col].astype(str).str.replace(',', '').str.replace(' ', '')
                    
                    df[col] = pd.to_numeric(df[col], errors='coerce')
            
            # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù†ØµÙŠØ©
            text_columns = [
                'Asset_Description', 'ÙˆØµÙ Ø§Ù„Ø£ØµÙ„',
                'Custodian', 'Ø§Ù„Ù‚Ø³Ù… Ø£Ùˆ Ø§Ù„Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ù…Ø³Ø¤ÙˆÙ„Ø©', 
                'City', 'Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©',
                'Level_1_FA_Module_English_Description', 'ÙˆØµÙ ØªØµÙ†ÙŠÙ Ø§Ù„Ø£ØµÙˆÙ„ Ø§Ù„Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø£ÙˆÙ„ - Ø§Ù†Ø¬Ù„ÙŠØ²ÙŠ',
                'Manufacturer', 'Ø§Ù„Ù…ØµÙ†Ø¹',
                'Tag_number', 'Ø±Ù‚Ù… Ø§Ù„Ø¨Ø·Ø§Ù‚Ø©'
            ]
            
            for col in text_columns:
                if col in df.columns:
                    df[col] = df[col].astype(str).str.strip()
                    # Ø§Ø³ØªØ¨Ø¯Ø§Ù„ 'Not Available' Ùˆ 'N/A' Ø¨Ù‚ÙŠÙ… ÙØ§Ø±ØºØ©
                    df[col] = df[col].replace(['Not Available', 'N/A', 'nan', 'None'], '')
            
            return df
            
        except Exception as e:
            st.warning(f"âš ï¸ ØªØ­Ø°ÙŠØ± ÙÙŠ ØªÙ†Ø¸ÙŠÙ Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {str(e)}")
            return df
    
    def handle_missing_values(self, df):
        """Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø©"""
        try:
            missing_report = {}
            
            for col in df.columns:
                missing_count = df[col].isna().sum()
                if missing_count > 0:
                    missing_percentage = (missing_count / len(df)) * 100
                    missing_report[col] = {
                        'count': missing_count,
                        'percentage': round(missing_percentage, 2)
                    }
                    
                    # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø­Ø³Ø¨ Ù†ÙˆØ¹ Ø§Ù„Ø¹Ù…ÙˆØ¯
                    if col in ['Cost', 'Depreciation_amount', 'Net_Book_Value']:
                        df[col] = df[col].fillna(0)
                    elif col in ['Asset_Description', 'Custodian']:
                        df[col] = df[col].fillna('ØºÙŠØ± Ù…Ø­Ø¯Ø¯')
                    elif 'Date' in col:
                        # ØªØ±Ùƒ Ø§Ù„ØªÙˆØ§Ø±ÙŠØ® Ø§Ù„ÙØ§Ø±ØºØ© ÙƒÙ…Ø§ Ù‡ÙŠ
                        pass
            
            if missing_report:
                st.warning("âš ï¸ ÙŠÙˆØ¬Ø¯ Ù‚ÙŠÙ… Ù…ÙÙ‚ÙˆØ¯Ø© ÙÙŠ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª")
                for col, info in missing_report.items():
                    if info['percentage'] > 5:  # ÙÙ‚Ø· Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ù†Ø³Ø¨Ø© ÙƒØ¨ÙŠØ±Ø©
                        st.write(f"   - {col}: {info['count']} Ù‚ÙŠÙ… Ù…ÙÙ‚ÙˆØ¯Ø© ({info['percentage']}%)")
            
            return df
            
        except Exception as e:
            st.warning(f"âš ï¸ ØªØ­Ø°ÙŠØ± ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø©: {str(e)}")
            return df
    
    def add_calculated_columns(self, df):
        """Ø¥Ø¶Ø§ÙØ© Ø£Ø¹Ù…Ø¯Ø© Ù…Ø­Ø³ÙˆØ¨Ø©"""
        try:
            # Ø­Ø³Ø§Ø¨ Ø¹Ù…Ø± Ø§Ù„Ø£ØµÙ„ (Ø¨Ø§Ù„Ø³Ù†ÙˆØ§Øª)
            if 'Date_Placed_in_Service' in df.columns:
                current_date = pd.Timestamp.now()
                df['Asset_Age_Years'] = ((current_date - pd.to_datetime(df['Date_Placed_in_Service'])) / np.timedelta64(1, 'Y')).round(1)
            
            # Ø­Ø³Ø§Ø¨ Ù†Ø³Ø¨Ø© Ø§Ù„Ø¥Ù‡Ù„Ø§Ùƒ
            if 'Cost' in df.columns and 'Depreciation_amount' in df.columns:
                df['Depreciation_Rate'] = (df['Depreciation_amount'] / df['Cost'] * 100).round(2)
                # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù‚ÙŠÙ… ØºÙŠØ± Ø§Ù„Ù…Ù†Ø·Ù‚ÙŠØ©
                df['Depreciation_Rate'] = df['Depreciation_Rate'].clip(0, 100)
            
            # ØªØµÙ†ÙŠÙ Ø­Ø§Ù„Ø© Ø§Ù„Ø£ØµÙ„
            if 'Depreciation_Rate' in df.columns:
                conditions = [
                    df['Depreciation_Rate'] >= 80,
                    df['Depreciation_Rate'] >= 50,
                    df['Depreciation_Rate'] >= 20,
                    df['Depreciation_Rate'] > 0
                ]
                choices = ['Ù‚Ø¯ÙŠÙ…', 'Ù…ØªÙˆØ³Ø·', 'Ø¬Ø¯ÙŠØ¯', 'Ø¬Ø¯ÙŠØ¯ Ø¬Ø¯Ø§Ù‹']
                df['Asset_Condition'] = np.select(conditions, choices, default='Ù„Ù… ÙŠØ¨Ø¯Ø£ Ø§Ù„Ø¥Ù‡Ù„Ø§Ùƒ')
            
            # ØªØµÙ†ÙŠÙ Ù‚ÙŠÙ…Ø© Ø§Ù„Ø£ØµÙ„
            if 'Cost' in df.columns:
                conditions = [
                    df['Cost'] >= 10000,
                    df['Cost'] >= 5000,
                    df['Cost'] >= 1000
                ]
                choices = ['Ø¹Ø§Ù„ÙŠØ©', 'Ù…ØªÙˆØ³Ø·Ø©', 'Ù…Ù†Ø®ÙØ¶Ø©']
                df['Value_Category'] = np.select(conditions, choices, default='very_low')
            
            # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¹Ù…Ø± Ø§Ù„Ù…ØªØ¨Ù‚ÙŠ
            if 'Useful_Life' in df.columns and 'Asset_Age_Years' in df.columns:
                df['Remaining_Life'] = (df['Useful_Life'] - df['Asset_Age_Years']).round(1)
                df['Remaining_Life'] = df['Remaining_Life'].clip(0)  # Ù„Ø§ ØªØ³Ù…Ø­ Ø¨Ù‚ÙŠÙ… Ø³Ø§Ù„Ø¨Ø©
            
            # Ø¥Ø¶Ø§ÙØ© Ø³Ù†Ø© Ø§Ù„ØªØ´ØºÙŠÙ„
            if 'Date_Placed_in_Service' in df.columns:
                df['Service_Year'] = pd.to_datetime(df['Date_Placed_in_Service']).dt.year
            
            st.info("ğŸ“ˆ ØªÙ… Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…Ø­Ø³ÙˆØ¨Ø© Ø¨Ù†Ø¬Ø§Ø­")
            return df
            
        except Exception as e:
            st.warning(f"âš ï¸ ØªØ­Ø°ÙŠØ± ÙÙŠ Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…Ø­Ø³ÙˆØ¨Ø©: {str(e)}")
            return df
    
    def validate_data_quality(self, df):
        """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø¬ÙˆØ¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
        try:
            issues = []
            
            # 1. Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ØªÙƒØ§Ù„ÙŠÙ Ø§Ù„Ø³Ù„Ø¨ÙŠØ©
            if 'Cost' in df.columns:
                negative_costs = df[df['Cost'] < 0]
                if len(negative_costs) > 0:
                    issues.append(f"âŒ ØªÙƒØ§Ù„ÙŠÙ Ø³Ù„Ø¨ÙŠØ©: {len(negative_costs)} Ø³Ø¬Ù„")
            
            # 2. Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø¥Ù‡Ù„Ø§Ùƒ Ø§Ù„Ø²Ø§Ø¦Ø¯
            if 'Cost' in df.columns and 'Depreciation_amount' in df.columns:
                excess_depreciation = df[df['Depreciation_amount'] > df['Cost']]
                if len(excess_depreciation) > 0:
                    issues.append(f"âŒ Ø¥Ù‡Ù„Ø§Ùƒ Ø²Ø§Ø¦Ø¯ Ø¹Ù† Ø§Ù„ØªÙƒÙ„ÙØ©: {len(excess_depreciation)} Ø³Ø¬Ù„")
            
            # 3. Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ø¯ÙØªØ±ÙŠØ© Ø§Ù„Ø³Ù„Ø¨ÙŠØ©
            if 'Net_Book_Value' in df.columns:
                negative_nbv = df[df['Net_Book_Value'] < 0]
                if len(negative_nbv) > 0:
                    issues.append(f"âŒ Ù‚ÙŠÙ… Ø¯ÙØªØ±ÙŠØ© Ø³Ù„Ø¨ÙŠØ©: {len(negative_nbv)} Ø³Ø¬Ù„")
            
            # 4. Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø£Ø¹Ù…Ø§Ø± ØºÙŠØ± Ø§Ù„Ù…Ù†Ø·Ù‚ÙŠØ©
            if 'Asset_Age_Years' in df.columns:
                negative_age = df[df['Asset_Age_Years'] < 0]
                if len(negative_age) > 0:
                    issues.append(f"âŒ Ø£Ø¹Ù…Ø§Ø± Ø³Ù„Ø¨ÙŠØ©: {len(negative_age)} Ø³Ø¬Ù„")
            
            # 5. Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ØªÙƒØ±Ø§Ø±
            if 'Tag_number' in df.columns:
                duplicates = df[df.duplicated('Tag_number', keep=False)]
                if len(duplicates) > 0:
                    issues.append(f"âŒ Ø£Ø±Ù‚Ø§Ù… Ø¨Ø·Ø§Ù‚Ø§Øª Ù…ÙƒØ±Ø±Ø©: {len(duplicates)} Ø³Ø¬Ù„")
            
            if issues:
                st.warning("âš ï¸ Ù…Ø´Ø§ÙƒÙ„ ÙÙŠ Ø¬ÙˆØ¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª:")
                for issue in issues:
                    st.write(f"   {issue}")
            else:
                st.success("âœ… Ø¬ÙˆØ¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù…ØªØ§Ø²Ø©")
                
            return issues
            
        except Exception as e:
            st.warning(f"âš ï¸ ØªØ­Ø°ÙŠØ± ÙÙŠ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø¬ÙˆØ¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {str(e)}")
            return []
    
    def get_data_summary(self, df):
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù…Ù„Ø®Øµ Ù„Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
        try:
            summary = {
                'total_records': len(df),
                'total_columns': len(df.columns),
                'data_types': df.dtypes.value_counts().to_dict(),
                'date_range': None,
                'cost_range': None
            }
            
            # Ù†Ø·Ø§Ù‚ Ø§Ù„ØªÙˆØ§Ø±ÙŠØ®
            if 'Date_Placed_in_Service' in df.columns:
                date_col = pd.to_datetime(df['Date_Placed_in_Service'])
                summary['date_range'] = {
                    'min': date_col.min(),
                    'max': date_col.max()
                }
            
            # Ù†Ø·Ø§Ù‚ Ø§Ù„ØªÙƒØ§Ù„ÙŠÙ
            if 'Cost' in df.columns:
                summary['cost_range'] = {
                    'min': df['Cost'].min(),
                    'max': df['Cost'].max(),
                    'total': df['Cost'].sum()
                }
            
            return summary
            
        except Exception as e:
            st.warning(f"âš ï¸ ØªØ­Ø°ÙŠØ± ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ø®Øµ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {str(e)}")
            return {}
    
    def export_processed_data(self, df, file_path):
        """ØªØµØ¯ÙŠØ± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©"""
        try:
            df.to_excel(file_path, index=False)
            st.success(f"âœ… ØªÙ… ØªØµØ¯ÙŠØ± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¥Ù„Ù‰ {file_path}")
            return True
        except Exception as e:
            st.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØµØ¯ÙŠØ± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {str(e)}")
            return False
    
    def filter_data(self, df, filters):
        """ØªØµÙÙŠØ© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø­Ø³Ø¨ Ù…Ø¹Ø§ÙŠÙŠØ± Ù…Ø­Ø¯Ø¯Ø©"""
        try:
            filtered_df = df.copy()
            
            for column, value in filters.items():
                if value and column in filtered_df.columns:
                    if isinstance(value, (int, float)):
                        filtered_df = filtered_df[filtered_df[column] == value]
                    else:
                        filtered_df = filtered_df[filtered_df[column].astype(str).str.contains(str(value), case=False, na=False)]
            
            return filtered_df
            
        except Exception as e:
            st.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØµÙÙŠØ© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {str(e)}")
            return df

class DataValidator:
    """ÙØ¦Ø© Ù„Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
    
    @staticmethod
    def validate_asset_data(df):
        """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø£ØµÙˆÙ„"""
        validation_results = {
            'passed': [],
            'warnings': [],
            'errors': []
        }
        
        try:
            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø­Ù‚ÙˆÙ„ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
            required_columns = ['Cost', 'Asset_Description', 'Tag_number']
            for col in required_columns:
                if col not in df.columns:
                    validation_results['errors'].append(f"Ø§Ù„Ø¹Ù…ÙˆØ¯ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ '{col}' ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯")
            
            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø£Ø±Ù‚Ø§Ù… Ø§Ù„Ø¨Ø·Ø§Ù‚Ø§Øª Ø§Ù„ÙØ±ÙŠØ¯Ø©
            if 'Tag_number' in df.columns:
                duplicate_tags = df[df.duplicated('Tag_number', keep=False)]
                if len(duplicate_tags) > 0:
                    validation_results['warnings'].append(f"ÙŠÙˆØ¬Ø¯ {len(duplicate_tags)} Ø±Ù‚Ù… Ø¨Ø·Ø§Ù‚Ø© Ù…ÙƒØ±Ø±")
            
            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ø±Ù‚Ù…ÙŠØ©
            numeric_columns = ['Cost', 'Depreciation_amount', 'Net_Book_Value']
            for col in numeric_columns:
                if col in df.columns:
                    if df[col].isna().any():
                        validation_results['warnings'].append(f"ÙŠÙˆØ¬Ø¯ Ù‚ÙŠÙ… Ù…ÙÙ‚ÙˆØ¯Ø© ÙÙŠ {col}")
                    if (df[col] < 0).any():
                        validation_results['warnings'].append(f"ÙŠÙˆØ¬Ø¯ Ù‚ÙŠÙ… Ø³Ù„Ø¨ÙŠØ© ÙÙŠ {col}")
            
            if not validation_results['errors']:
                validation_results['passed'].append("Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© Ù†Ø¬Ø­Øª")
            
            return validation_results
            
        except Exception as e:
            validation_results['errors'].append(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {str(e)}")
            return validation_results

# Ø¯ÙˆØ§Ù„ Ù…Ø³Ø§Ø¹Ø¯Ø©
def detect_data_patterns(df):
    """ÙƒØ´Ù Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
    patterns = {}
    
    try:
        # Ù†Ù…Ø· Ø§Ù„ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø²Ù…Ù†ÙŠ
        if 'Service_Year' in df.columns:
            yearly_pattern = df['Service_Year'].value_counts().sort_index()
            patterns['yearly_distribution'] = yearly_pattern.to_dict()
        
        # Ù†Ù…Ø· Ø§Ù„ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø¬ØºØ±Ø§ÙÙŠ
        if 'City' in df.columns:
            city_pattern = df['City'].value_counts()
            patterns['city_distribution'] = city_pattern.to_dict()
        
        # Ù†Ù…Ø· Ø§Ù„ØªØµÙ†ÙŠÙ
        if 'Level_1_FA_Module_English_Description' in df.columns:
            category_pattern = df['Level_1_FA_Module_English_Description'].value_counts()
            patterns['category_distribution'] = category_pattern.to_dict()
        
        return patterns
        
    except Exception as e:
        st.warning(f"âš ï¸ ØªØ­Ø°ÙŠØ± ÙÙŠ ÙƒØ´Ù Ø§Ù„Ø£Ù†Ù…Ø§Ø·: {str(e)}")
        return {}

def generate_data_report(df):
    """Ø¥Ù†Ø´Ø§Ø¡ ØªÙ‚Ø±ÙŠØ± Ø´Ø§Ù…Ù„ Ø¹Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
    report = {
        'basic_info': {
            'total_records': len(df),
            'total_columns': len(df.columns),
            'memory_usage': df.memory_usage(deep=True).sum() / 1024**2  # Ø¨Ø§Ù„Ù…ÙŠØ¬Ø§Ø¨Ø§ÙŠØª
        },
        'data_quality': {},
        'patterns': detect_data_patterns(df)
    }
    
    return report
